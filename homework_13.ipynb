{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torchvision.transforms as transforms  \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data for node 1 succesfully created\n",
      "data for node 2 succesfully created\n",
      "data for node 3 succesfully created\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"D:\\Training\\itHillel\\Machine Learning\\Lesson_12\\celeba\"\n",
    "celeba_raw_folder = os.path.join(\"Celeba_raw\", \"raw\")\n",
    "img_dir = os.path.join(parent_dir, celeba_raw_folder, \"img_align_celeba\") + os.sep\n",
    "out_dir = os.path.join(parent_dir, \"celeba_preprocessed\")\n",
    "\n",
    "columns = [\"Smiling\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(parent_dir, celeba_raw_folder, \"list_attr_celeba.txt\"),\n",
    "    sep=\"\\s+\",\n",
    "    skiprows=1,\n",
    "    usecols=columns,\n",
    ")\n",
    "\n",
    "\n",
    "df.loc[df[\"Smiling\"] == -1, \"Smiling\"] = 0\n",
    "\n",
    "\n",
    "length = len(df)\n",
    "data_node_1 = df.iloc[: int(length / 3)]\n",
    "data_node_2 = df.iloc[int(length / 3) : int(length / 3) * 2]\n",
    "data_node_3 = df.iloc[int(length / 3) * 2 :]\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_1\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_1\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_2\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_2\", \"data\"))\n",
    "if not os.path.exists(os.path.join(out_dir, \"data_node_3\")):\n",
    "    os.makedirs(os.path.join(out_dir, \"data_node_3\", \"data\"))\n",
    "\n",
    "\n",
    "data_node_1.to_csv(os.path.join(out_dir, \"data_node_1\", \"target.csv\"), sep=\"\\t\")\n",
    "data_node_2.to_csv(os.path.join(out_dir, \"data_node_2\", \"target.csv\"), sep=\"\\t\")\n",
    "data_node_3.to_csv(os.path.join(out_dir, \"data_node_3\", \"target.csv\"), sep=\"\\t\")\n",
    "\n",
    "\n",
    "for im in data_node_1.index:\n",
    "    shutil.copy(img_dir + im, os.path.join(out_dir, \"data_node_1\", \"data\", im))\n",
    "print(\"data for node 1 succesfully created\")\n",
    "\n",
    "for im in data_node_2.index:\n",
    "    shutil.copy(img_dir + im, os.path.join(out_dir, \"data_node_2\", \"data\", im))\n",
    "print(\"data for node 2 succesfully created\")\n",
    "\n",
    "for im in data_node_3.index:\n",
    "    shutil.copy(img_dir + im, os.path.join(out_dir, \"data_node_3\", \"data\", im))\n",
    "print(\"data for node 3 succesfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, partition_file_path, root_dir, transform=None):\n",
    "        df = pd.read_csv(partition_file_path, sep=\"\\t\", index_col=0)\n",
    "        self.root_dir = root_dir\n",
    "        self.partition_file_path = partition_file_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Smiling'].values\n",
    "        self.transform = transform\n",
    "        print(\"celeba dataset finished\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.asarray(Image.open(os.path.join(self.root_dir, self.img_names[index])))\n",
    "        img = transforms.ToTensor()(np.array(img))\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeba dataset finished\n",
      "celeba dataset finished\n"
     ]
    }
   ],
   "source": [
    "data_root = \"D:\\Training\\itHillel\\Machine Learning\\Lesson_12\\celeba\\celeba_preprocessed\"\n",
    "trainset = CelebADataset(f\"{data_root}/data_node_2/target.csv\", f\"{data_root}\\data_node_2\\data\")\n",
    "testset = CelebADataset(f\"{data_root}/data_node_3/target.csv\", f\"{data_root}\\data_node_3\\data\")\n",
    "\n",
    "trainloader = DataLoader(trainset, shuffle=True)\n",
    "testloader = DataLoader(testset, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(3168, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=3168, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': {'batch_size': 32}, \n",
    "    'optimizer_args': {'lr': 0.1},\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "opt_sgd = torch.optim.SGD(\n",
    "    model.parameters(), lr=training_args[\"optimizer_args\"][\"lr\"]\n",
    ")\n",
    "\n",
    "opt_adam = torch.optim.Adam(model.parameters(), lr=training_args[\"optimizer_args\"][\"lr\"])\n",
    "opt_rmsprop = torch.optim.RMSprop(model.parameters(), lr=training_args[\"optimizer_args\"][\"lr\"])\n",
    "batch_size = training_args[\"loader_args\"][\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        pred = model(X)\n",
    "        loss_res = loss(pred, y)\n",
    "        loss_res.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "\n",
    "            loss_res, current = loss_res.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss_res:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    \n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.273250  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.695926 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.653140  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.696521 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.846256  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.693209 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.794491  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692542 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.616114  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.705742 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.501581  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692031 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.735716  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.708921 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.838850  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.694309 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.713489  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.704458 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.507957  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692420 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.619802  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692059 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.637486  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.696617 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.559533  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.694300 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.584333  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692089 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.729101  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.694223 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.585352  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.701195 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.784936  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.693804 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.680991  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.714975 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.874000  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.694135 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.586547  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.710374 \n",
      "\n",
      "Done!\n",
      "The time difference is : 29.452894899994135\n"
     ]
    }
   ],
   "source": [
    "starttime = timeit.default_timer()\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, opt_sgd)\n",
    "    test_loop(testloader, model)\n",
    "print(\"Done!\")\n",
    "print(\"The time difference is :\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.694770  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.712547 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.692100  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692409 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.936985  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.694507 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.573993  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.706439 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.805767  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.777698 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.377631  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.728856 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.429325  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.877058 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.424000  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.694801 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.666469  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.706881 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.575996  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.771908 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.337817  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.705257 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.814988  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.703497 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.594548  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.695422 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.658811  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.697567 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.858317  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.696742 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.644745  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.714383 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.870748  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.693290 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.690233  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.717918 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.528947  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.727365 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.935928  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.695854 \n",
      "\n",
      "Done!\n",
      "The time difference is : 33.634979799971916\n"
     ]
    }
   ],
   "source": [
    "starttime = timeit.default_timer()\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, opt_adam)\n",
    "    test_loop(testloader, model)\n",
    "print(\"Done!\")\n",
    "print(\"The time difference is :\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.733978  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692030 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.652179  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.729589 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.946083  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692033 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.652692  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.693131 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.602612  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.692558 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.777118  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.694900 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.665184  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.707738 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.831406  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.695554 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.833906  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.721415 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.516742  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.712790 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.977949  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.707527 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.572745  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.725466 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.927067  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.750410 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.032270  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.730290 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.489452  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.759095 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.422802  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.695229 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.573242  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.696024 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.652080  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.716484 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.882150  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.695314 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.727348  [    1/   83]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.823318 \n",
      "\n",
      "Done!\n",
      "The time difference is : 31.11783350002952\n"
     ]
    }
   ],
   "source": [
    "starttime = timeit.default_timer()\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, model, opt_rmsprop)\n",
    "    test_loop(testloader, model)\n",
    "print(\"Done!\")\n",
    "print(\"The time difference is :\", timeit.default_timer() - starttime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
